{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def envelope(th, theta, B_theta):\n",
    "    if B_theta==np.inf:\n",
    "        env = np.ones_like(th) \n",
    "    elif B_theta==0:\n",
    "        env = np.zeros_like(th)\n",
    "        env[np.argmin(th < theta)] = 1.\n",
    "    else:\n",
    "        env = np.exp((np.cos(2*(th-theta))-1)/4/B_theta**2)\n",
    "    return env/env.max()        \n",
    "\n",
    "N_theta = 12\n",
    "bins = 180\n",
    "th = np.linspace(0, np.pi, bins, endpoint=False)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 5))\n",
    "for i, B_theta_ in enumerate([np.pi/12, np.pi/4]):#[0, np.pi/64, np.pi/32, np.pi/16, np.pi/8, np.pi/4, np.pi/2, np.inf]:\n",
    "    for theta, color in zip(np.linspace(0, np.pi, N_theta, endpoint=False), \n",
    "                            [plt.cm.hsv(h) for h in np.linspace(0, 1, N_theta)]):\n",
    "        axs[i].plot(th*180/np.pi, envelope(th, theta, B_theta_), alpha=.6, color=color, lw=3)\n",
    "        axs[i].fill_between(th*180/np.pi, 0, envelope(th, theta, B_theta_), alpha=.1, color=color)\n",
    "    axs[i].set_xlim([0, 180])\n",
    "    axs[i].set_ylim([0, 1.1])\n",
    "    axs[i].set_xticks(np.linspace(0, 180, 5, endpoint=True) )#to specify number of tick…\n",
    "fig.savefig('../figs/tuning_functions.png', dpi = 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Arrow\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "\n",
    "def model(future=False):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    ax2 = fig.add_subplot(111, alpha=0., axis_bgcolor=(1,1,1,0))\n",
    "    ax = fig.add_subplot(111, projection='polar', alpha=0., axis_bgcolor=(1,1,1,0))\n",
    "\n",
    "    opts= dict(ha='center', fontsize=14)\n",
    "    N = 24\n",
    "    s = 42\n",
    "    theta = np.linspace(0, 2*np.pi, N+1, endpoint=True)\n",
    "\n",
    "    ## connexions\n",
    "    N_arrow = 3\n",
    "    dthetas = alphas = np.linspace(-N_arrow, N_arrow, 2*N_arrow+1, endpoint=True)\n",
    "    dthetas *= 1.75*np.pi/N\n",
    "    alphas = np.exp( - alphas**2/ .4**2 / 2)\n",
    "    #print(alphas)\n",
    "    for dtheta, alpha in zip(dthetas, alphas):\n",
    "        plt.arrow(np.pi/2, 1.4, dtheta, -.2, color='k', alpha=alpha)\n",
    "\n",
    "        plt.arrow(0, 1.1, dtheta, -.1, color='r', alpha=alpha)\n",
    "        plt.arrow(0, 1.1, dtheta, 0., color='r', alpha=alpha)\n",
    "\n",
    "        plt.arrow(np.pi, .9, dtheta, .1, color='b', alpha=alpha)\n",
    "        plt.arrow(np.pi, .9, dtheta, 0., color='b', alpha=alpha)\n",
    "        #set_connectionstyle(\"arc,angleA=0,armA=30,rad=10\")\n",
    "        #set_arrowstyle(\"Fancy,head_length=0.2\")\n",
    "\n",
    "    ## neurones\n",
    "    colors = theta\n",
    "    for r, c in zip([.9, 1.1, 1.4], ['b', 'r', 'k']):\n",
    "        ax.plot(theta, r*np.ones_like(theta), c=c, alpha=.4)\n",
    "        c = ax.scatter(theta[:-1], r*np.ones_like(theta[:-1]), c=c, s=s)\n",
    "        #c.set_alpha(0.15)\n",
    "\n",
    "    ## entrée\n",
    "    N = 1080\n",
    "    theta = np.linspace(0, 2*np.pi, N)\n",
    "    ax.fill_between(theta, 1.45, 1.45 + envelope(theta/2, np.pi/4, np.pi/24)/2.5, lw=0, color='g', alpha=.3)\n",
    "\n",
    "    ax.set_ylim((0, 1.85))\n",
    "\n",
    "    ax.text(-np.pi/2, 1.25, 'Excitateurs', **opts)\n",
    "    ax.text(-np.pi/2, .8, 'Inhibiteurs', **opts)\n",
    "    if future:\n",
    "\n",
    "        ax.text(np.pi/2, 1.6, 'Entrée\\ndirectionnelle', **opts)\n",
    "        ax.text(-np.pi/2, 1.55, 'convergence corticale', **opts)\n",
    "    else:\n",
    "        \n",
    "        ax.text(np.pi/2, 1.6, 'Entrée\\norientationnelle', **opts)\n",
    "        ax.text(-np.pi/2, 1.55, 'convergence thalamo-corticale', **opts)\n",
    "\n",
    "    N = 12\n",
    "    for theta in np.linspace(0, 2*np.pi, N, endpoint=False):\n",
    "        r, angle, l = .15, theta, .1\n",
    "        if future:\n",
    "            ax2.add_patch(Arrow((r-l/2)*np.sin(angle)+.5, (r-l/2)*np.cos(angle)+.5, l*np.sin(angle), l*np.cos(angle), width=.06, color='k'))\n",
    "        else:\n",
    "            ax2.add_patch(Rectangle([r*np.sin(angle)+.5, r*np.cos(angle)+.5], .01, .04, angle=theta/2*180/np.pi, color=hsv_to_rgb([theta/2/np.pi, 1, 1])))            \n",
    "\n",
    "    for ax_ in [ax, ax2]:\n",
    "        ax_.grid(False, axis='both')\n",
    "\n",
    "        ax_.set_xticks([])\n",
    "        ax_.set_yticks([])\n",
    "        ax_.set_axis_off()\n",
    "    \n",
    "    fig.subplots_adjust(hspace = .0, wspace = .0, left=0.01, bottom=0.01, right=.99, top=.99)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = model()\n",
    "fig.savefig('../figs/ring_model.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le Ring\n",
    "\n",
    "Une fois le RRNN créé, paramétré et optimisé, nous lui ajoutons certaines propriétés dans le but de le transformer en \"ring\". Ce dernier va nous permettre d'implémenter le modèle de la sélectivité à l'orientation reproduisant ce qui peut être observé au sein des colonnes corticales du cortex visuel primaire.\n",
    "\n",
    "Le ring est un réseau récurrent disposant d'une certaine topologie. En effet, selon sa position dans le réseau, un neurone possède une certaine sélectivité à l'orientation et les connexions sont locales dans l'espace des orientations. \n",
    "Quelques propriétés de la réponse à l'orientation vont conditionner cette sélectivité et induire un certain comportement du réseau, en réponse à une orientation présentée sur son entrée :\n",
    "\n",
    "-  $m$ est l'angle d'orientation préferée d'un neurone. Cela signifie que ce dernier aura une réponse maximale si une orientation d'un angle $\\theta$, tel que $\\theta = m$, est présentée. Notons que le ring est construit de telle sorte que toutes les orientations sont codées avec une précision de vingt minutes d'arc et qu'il est non orienté, ainsi $0\\leq m \\leq \\pi$.\n",
    "- la bandwidth $\\sigma$ est la largeur à mi-hauteur de la courbe d'accord d'un neurone. Elle sert à représenter la sélectivité de la réponse neuronale à d'autres orientations que celle préferée. Dans ce modèle, les bandwidth ne sont pas paramétrés par neurone mais plutôt par type de connexion entre les populations E et I. Nous implémentons également une bandwidth dans les connexions entre la source et la population E. Ainsi, nous cherchons à ce que les neurones d'une colonne corticale aient une certaine bandwith de sélectivité à l'orientation du fait de leurs connexions avec d'autres colonnes.\n",
    "\n",
    "Une fonction d'accord est aussi implémentée. Cette fonction permet de calculer le poids synaptique de chacune des connexions d'une projection à partir des propriétés décrites plus haut. De part sa généralité, nous utiliserons une loi de Von Mises (loi normale circulaire) définie par :\n",
    "\n",
    "$$\n",
    "f(\\theta) = \\frac{1}{Z(\\kappa)} \\cdot e^{\\kappa{cos(2(\\theta - m))}}\n",
    "$$\n",
    "où $Z$ est la fonction de normalisation. Par analogie avec la déviation standard d'une loi Gaussienne, on définit $\\kappa = \\frac {1}{\\sigma^{2}}$. Notons que $f(\\theta+\\pi) = f(\\theta)$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import MotionClouds as mc\n",
    "import matplotlib.pyplot as plt\n",
    "downscale = 1\n",
    "fx, fy, ft = mc.get_grids(mc.N_X/downscale, mc.N_Y/downscale, 16)\n",
    "\n",
    "\n",
    "N_theta = 6\n",
    "bw_values = np.pi*np.logspace(-2, -5, N_theta, base=2)\n",
    "fig_width = 21\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, N_theta, figsize=(fig_width, fig_width/N_theta))\n",
    "for i_ax, B_theta in enumerate(bw_values):\n",
    "    mc_i = mc.envelope_gabor(fx, fy, ft, V_X=0., V_Y=0.,  \n",
    "                                         theta=np.pi/2, B_theta=B_theta)\n",
    "    im = mc.random_cloud(mc_i)\n",
    "                \n",
    "    axs[i_ax].imshow(im[:, :, 0], cmap=plt.gray())\n",
    "    axs[i_ax].text(5, 29, r'$B_\\theta=%.1f$°' % (B_theta*180/np.pi), color='white', fontsize=32)\n",
    "    axs[i_ax].set_xticks([])\n",
    "    axs[i_ax].set_yticks([])\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(hspace = .0, wspace = .0, left=0.0, bottom=0., right=1., top=1.)\n",
    "\n",
    "import os\n",
    "fig.savefig(os.path.join('../figs', 'orientation_tuning.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le ring feed-forward face au ring récurrent\n",
    "\n",
    "### Différences dans les motifs d'activité\n",
    "\n",
    "Ici, nous montrons les différences d'activité entre un ring avec une connectivité feed- forward et un ring possédant une connectivité récurrente. La population excitatrice d'un ring récurrent bien accordé doit représenter de façon précise l'orientation soumise en entrée même si la distibution d'orientation à une grande largeur de bande. \n",
    "\n",
    "Pour vérifier cela, nous paramétrons l'activité des neurones de la population source de telle sorte que celle-ci représente une orientation de contraste de 90° et que la largeur de bande de la distribution soumise soit de 40°. Nous générons alors les rasterplots des trois populations du ring feed-forward ainsi que du ring récurrent.\n",
    "\n",
    "Si l'on s'intéresse à l'activité de la population excitatrice pour chacun des deux types de ring, nous observons bien que le ring feed-forward reproduit l'activité de la population d'entrée alors que le ring récurrent présente une activité plus locale. Et, puisque les neurones du ring sont organisés selon leur préference à l'orientation, cela signifie que la connectivité récurrente entraine une représentation de l'orientation plus précise. Ainsi la réponse du ring recurrent est plus robuste à l'imprecision de l'orientation présentée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Différences dans les courbes d'accord\n",
    "\n",
    "Par un ajustement de la distribution de Von Mises aux taux de décharge de la population excitatrice, nous tentons maintenant de montrer, de façon plus quantitative, l'effet de chacun des deux types de connectivité.\n",
    "\n",
    "Nous simulons donc le ring feed-forward et le ring récurrent avec différentes entrées, des distributions d'orientation ayant différentes largeurs de bande. Pour chacun des deux types de ring, nous mesurons le taux de décharge moyen de la population excitatrice et nous ajustons ensuite ces taux de décharge par des distributions de Von Mises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RRNN import RRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bw_values = 180*np.logspace(0, -4, 5, base=2)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for i in range(2):#, w in enumerate([0., .32]):\n",
    "    for bw_value in bw_values:\n",
    "        if i==0:\n",
    "            net = RRNN(ring=False, recurrent=False)\n",
    "        else:\n",
    "            net = RRNN(ring=True, recurrent=True)\n",
    "\n",
    "        net.sim_params['b_input'] = bw_value\n",
    "        df, spikesE, spikesI = net.model()\n",
    "        theta, fr, result = net.fit_vonMises(spikesE)\n",
    "        #print(result.best_fit.mean())\n",
    "        axs[i].plot(theta*180/np.pi, result.best_fit, label=str(bw_value))\n",
    "\n",
    "    axs[i].set_xlabel('orientation')\n",
    "    axs[i].set_ylabel('firing rate')\n",
    "    axs[i].axis('tight')\n",
    "    axs[i].set_ylim([0, 30])\n",
    "axs[0].set_title('feed-forward ring')\n",
    "axs[1].set_title('recurrent ring')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../figs/ring_feed-forward_vs_recurrent.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bw_values = 180*np.logspace(-1, -10, 15, base=2)\n",
    "\n",
    "def HWHH(k):\n",
    "    \"\"\"\n",
    "    See http://motionclouds.invibe.net/posts/testing-grating.html#tuning-the-bandwidth\n",
    "    \n",
    "    \"\"\"\n",
    "    return .5*np.arccos(1+ np.log((1+np.exp(-2*k))/2)/k)\n",
    "\n",
    "HWHH_in = HWHH(1/np.sqrt(bw_values/180*np.pi))\n",
    "\n",
    "print(bw_values, HWHH_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BW= np.zeros((2, len(bw_values)))\n",
    "for i in range(2):\n",
    "    for i_bw, bw_value in enumerate(bw_values):\n",
    "        if i==0:\n",
    "            net = RRNN(ring=False, recurrent=False)\n",
    "        else:\n",
    "            net = RRNN(ring=True, recurrent=True)\n",
    "\n",
    "        net.sim_params['b_input'] = bw_value\n",
    "        \n",
    "        df, spikesE, spikesI = net.model()\n",
    "        theta, fr, result = net.fit_vonMises(spikesE)\n",
    "        BW[i, i_bw] = result.params['sigma'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.plot(HWHH_in, HWHH(1/np.sqrt(BW[0, :])), 'k.', label='feed-forward ring')\n",
    "ax.plot(HWHH_in, HWHH(1/np.sqrt(BW[1, :])), 'r.', label='recurrent ring')\n",
    "        \n",
    "ax.set_xlabel('HWHH in')\n",
    "ax.set_ylabel('HWHH out')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "ax.axis('tight')\n",
    "ax.set_xlim([0, .7])\n",
    "ax.set_ylim([0, .7])\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../figs/ring_feed-forward_vs_recurrent_BW.png', dpi = 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bw_values, BW[0, :], BW[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
