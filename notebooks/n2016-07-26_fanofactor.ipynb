{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSAConnector: libneurosim support not available in NEST.\n",
      "Falling back on PyNN's default CSAConnector.\n",
      "Please re-compile NEST using --with-libneurosim=PATH\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/__init__.py:1314: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "/usr/local/lib/python2.7/dist-packages/NeuroTools/__init__.py:125: DependencyWarning: ** interval ** package is not installed.\n",
      "To have functions using interval please install the package.\n",
      "website : http://pypi.python.org/pypi/interval/1.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from RRNN import RRNN\n",
    "from NeuroTools.signals.spikes import SpikeTrain\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/daav/opt/nest/lib/python2.7/site-packages/nest/lib/hl_api_helper.py:61: UserWarning: \n",
      "ConvergentConnect is deprecated and will be removed in a future version of NEST.\n",
      "Please use Connect instead!\n",
      "For details, see http://www.nest-simulator.org/connection_management                       \n",
      "Fano factor : 0.0\n",
      "Fano factor : 0.0\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No spikes in the SpikeTrain !",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7fd71d0ee65c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mspiketrain\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mspikesE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspiketrains\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'Fano factor : {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSpikeTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspiketrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfano_factor_isi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/NeuroTools/signals/spikes.pyc\u001b[0m in \u001b[0;36mfano_factor_isi\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No spikes in the SpikeTrain !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtime_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_bin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No spikes in the SpikeTrain !"
     ]
    }
   ],
   "source": [
    "net = RRNN(recurrent=True, ring=False)\n",
    "df, spikesE, spikesI = net.model()\n",
    "\n",
    "for spiketrain in spikesE.spiketrains:\n",
    "    print 'Fano factor : {0}'.format(SpikeTrain(spiketrain).fano_factor_isi())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fano factor forces us to manage case of silent neurons. Another possible approach is to compute an equivalent index using cv of collapsed activity of population neurons over cvs mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 6], [1, 3, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (A.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.unique(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.unique() is apparently the function to use with our spiketrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab = np.array(spikesE.spiketrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(tab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tab = np.array([])\n",
    "for st in spikesE.spiketrains:\n",
    "    tab = np.append(tab, np.array(st), axis=0)\n",
    "print tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab2 = np.unique(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (tab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_collapsedspikes = SpikeTrain(tab2).cv_isi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print cv_collapsedspikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_CVs = np.array([])\n",
    "for st in spikesE.spiketrains :\n",
    "    all_CVs = np.append(all_CVs, SpikeTrain(np.array(st)).cv_isi())\n",
    "meanCv = np.nanmean(all_CVs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(meanCv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fakefano = cv_collapsedspikes/meanCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print fakefano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a little test with poisson process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyNN.nest as sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim.setup(timestep=0.1)\n",
    "\n",
    "poisson = sim.Population(100, sim.SpikeSourcePoisson(rate=10))\n",
    "poisson.record('spikes')\n",
    "\n",
    "sim.run(1000)\n",
    "poisson_spikes = poisson.get_data().segments[0]\n",
    "\n",
    "tab = np.array([])\n",
    "for st in poisson_spikes.spiketrains:\n",
    "    tab = np.append(tab, np.array(st), axis=0)\n",
    "\n",
    "cv_collapsed = SpikeTrain(np.unique(tab)).cv_isi()\n",
    "\n",
    "all_CVs = np.array([])\n",
    "for st in poisson_spikes.spiketrains :\n",
    "    all_CVs = np.append(all_CVs, SpikeTrain(np.array(st)).cv_isi())\n",
    "\n",
    "meanCv = np.nanmean(all_CVs)\n",
    "\n",
    "fakefano = cv_collapsed/meanCv\n",
    "\n",
    "print fakefano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(poisson_spikes.spiketrains[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyspike\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%bash\n",
    "cd ~/Downloads\n",
    "git clone https://github.com/mariomulansky/PySpike.git\n",
    "cd PySpike\n",
    "python setup.py build_ext --inplace\n",
    "python setup.py build\n",
    "python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reliability(spike_data, method='purpura'):\n",
    "    spike_trains = []    \n",
    "    for st_ in spike_data:\n",
    "        spike_trains.append(st_)\n",
    "\n",
    "    if method=='pyspike':\n",
    "        import pyspike as spk\n",
    "        spike_trains = [ spk.SpikeTrain(st_, edges=(0, params['block_duration'])) for st_ in spike_trains]   # spike_trains.append(spk.SpikeTrain(st_, edges=(0, params['block_duration'])))\n",
    "\n",
    "        #from pyspike import spike_sync_profile as profile # , max_tau=1000\n",
    "        from pyspike import spike_profile as profile\n",
    "        spk.disable_backend_warning = True\n",
    "        avrg_profile = profile(spike_trains).avrg()\n",
    "\n",
    "    elif method=='purpura':\n",
    "        import elephant\n",
    "        from neo.core import SpikeTrain\n",
    "        from quantities import s\n",
    "\n",
    "        #spike_trains = [ SpikeTrain(st_*s, t_stop=1*s) for st_ in spike_trains] \n",
    "        #for st_ in spike_data[:8]: # HACK to remove the last trials which seem weak\n",
    "        #    spike_trains.append(SpikeTrain(st_*s, t_stop=params['block_duration']*s))\n",
    "        D = elephant.spike_train_dissimilarity.victor_purpura_dist(spike_trains)\n",
    "        avrg_profile = D.mean()\n",
    "\n",
    "    elif method=='van_rossum':\n",
    "        import elephant\n",
    "        from neo.core import SpikeTrain\n",
    "        from quantities import s\n",
    "\n",
    "        spike_trains = [ SpikeTrain(st_*s, t_stop=params['block_duration']*s) for st_ in spike_trains] \n",
    "        #for st_ in spike_data[:8]: # HACK to remove the last trials which seem weak\n",
    "        #    spike_trains.append(SpikeTrain(st_*s, t_stop=params['block_duration']*s))\n",
    "        D = elephant.spike_train_dissimilarity.van_rossum_dist(spike_trains, tau=np.array(1.0) * s)\n",
    "        avrg_profile = D.mean()\n",
    "\n",
    "    return avrg_profile\n",
    "            \n",
    "\n",
    "print (\"reliability = \" + \"{0:.4f}\".format(reliability(poisson_spikes.spiketrains)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = RRNN(recurrent=True, ring=False)\n",
    "df, spikesE, spikesI = net.model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (\"reliability = \" + \"{0:.4f}\".format(reliability(spikesE.spiketrains)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
